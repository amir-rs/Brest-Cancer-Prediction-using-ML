# -*- coding: utf-8 -*-
"""breast_cancer_pred_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sN3wKcfoRo-vxxHmrT5rV1qcQLqtIPGs
"""

# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder , StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score , confusion_matrix , make_scorer
from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import sklearn.datasets
from xgboost import XGBClassifier
from sklearn.svm import SVC
# Suppress warnings for cleaner output
import warnings
warnings.filterwarnings("ignore")

# Load breast cancer dataset

breast_cancer_dataset = sklearn.datasets.load_breast_cancer()

print(breast_cancer_dataset)

# Create DataFrame from dataset
df = pd.DataFrame(breast_cancer_dataset.data, columns=breast_cancer_dataset.feature_names)

df.head(10)

# Add target labels to DataFrame

df['label'] = breast_cancer_dataset.target

"""# Data Exploration

"""

df.head(10)

# Print shape of DataFrame
df.shape

# Print information about DataFrame
df.info()

# Check for missing values
df.isnull().sum()

# Descriptive statistics of DataFrame
df.describe()

#Count of each class

df['label'].value_counts()

# Mean of features by class

df.groupby('label').mean()

description = df.describe()
print(f'description of the dataset  : {description}')

corr=df.corr()
corr

df.std()

# Visualizations

selected_features = ['area error', 'worst perimeter', 'worst area', 'mean area',
                    'mean perimeter']

sns.pairplot(df , vars=selected_features, hue='label', markers=['o','s'], palette='husl')
plt.show()

sns.countplot(x='label', data=df)

sns.distplot(df['label'])

sns.displot(df['label'])

plt.figure(figsize=(10,10))
sns.heatmap(corr , cbar=True , square=True , fmt='.1f', annot=True,
           annot_kws={'size':8}, cmap='Blues')

X = df.drop(columns='label', axis=1)
y = df['label']

print(X)
print(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

y_train.unique()

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(model,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model = AdaBoostClassifier(random_state=42)
grid_search = GridSearchCV(model,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model = XGBClassifier(random_state=42)
grid_search = GridSearchCV(model,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

!pip install  catboost

'''param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model = CatBoostClassifier(random_state=42)
grid_search = GridSearchCV(model,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)'''

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)

X_train_predict = model.predict(X_train)

training = accuracy_score(y_train, X_train_predict)

print(training)

model = RandomForestClassifier(n_estimators=200 , random_state=42)
model.fit(X_train,y_train)
y_perd = model.predict(X_test)
accuracy = accuracy_score(y_test,y_perd)
precision = precision_score(y_test,y_perd)
recall = recall_score(y_test,y_perd)
f1 = f1_score(y_test,y_perd)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'precision :  {precision:.2f}%')
print(f'recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')

model = AdaBoostClassifier(n_estimators=300 , random_state=42)
model.fit(X_train,y_train)
y_perd = model.predict(X_test)
accuracy = accuracy_score(y_test,y_perd)
precision = precision_score(y_test,y_perd)
recall = recall_score(y_test,y_perd)
f1 = f1_score(y_test,y_perd)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'precision :  {precision:.2f}%')
print(f'recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')

from xgboost import XGBClassifier
model = XGBClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test,y_perd)
precision = precision_score(y_test,y_perd)
recall = recall_score(y_test,y_perd)
f1 = f1_score(y_test,y_perd)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'precision :  {precision:.2f}%')
print(f'recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')

from catboost import CatBoostClassifier
model = CatBoostClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test,y_perd)
precision = precision_score(y_test,y_perd)
recall = recall_score(y_test,y_perd)
f1 = f1_score(y_test,y_perd)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'precision :  {precision:.2f}%')
print(f'recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')

model = SVC(kernel='linear', random_state=42)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test,y_perd)
precision = precision_score(y_test,y_perd)
recall = recall_score(y_test,y_perd)
f1 = f1_score(y_test,y_perd)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'precision :  {precision:.2f}%')
print(f'recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')

# Define models for ROC curve plotting

from sklearn.metrics import roc_curve, auc

models = [
    RandomForestClassifier(n_estimators=200, random_state=42),
    AdaBoostClassifier(n_estimators=300, random_state=42),
    SVC(kernel='linear', probability=True, random_state=42),
    CatBoostClassifier(n_estimators=200, random_state=42, verbose=False),
    XGBClassifier(n_estimators=200, random_state=42),
    LogisticRegression()
]
# Plot ROC curve for each model

plt.figure(figsize=(10, 8))
for model in models:
    model.fit(X_train, y_train)
    y_score = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label='%s (AUC = %0.2f)' % (type(model).__name__, roc_auc))

plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.show()